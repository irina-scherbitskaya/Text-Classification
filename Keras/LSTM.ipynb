{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hxgCJqmyVE-H",
    "outputId": "7bf020a4-9b3e-47d0-d2d7-5fcc969b5e3f"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import roc_auc_score, precision_score, log_loss, accuracy_score\n",
    "from keras.layers import Input, Dropout, Dense, LSTM,  Embedding, \\\n",
    "GlobalAveragePooling1D, Bidirectional, GlobalMaxPooling1D, SpatialDropout1D\n",
    "import keras.utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import concatenate\n",
    "import keras.backend as K\n",
    "from keras.initializers import Constant \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "w2v = KeyedVectors.load(\"train.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eAUlARW_VE-J"
   },
   "outputs": [],
   "source": [
    "def model_rnn(num_words, emb_dim, emb_matrix, max_len):\n",
    "    rec_units = 128\n",
    "    input_layer = Input(shape=(max_len,))\n",
    "    emb_layer = Embedding(num_words + 1,\n",
    "                                emb_dim,\n",
    "                                weights=[emb_matrix],\n",
    "                                input_length=max_len,\n",
    "                                trainable=False)(input_layer)\n",
    "    emb_layer = SpatialDropout1D(0.2)(emb_layer)\n",
    "    layer = Bidirectional(LSTM(rec_units, return_sequences=True))(emb_layer)\n",
    "    layer = SpatialDropout1D(0.2)(layer)\n",
    "    layer = Bidirectional(LSTM(rec_units, return_sequences=True))(layer)\n",
    "    maxpool = GlobalMaxPooling1D()(layer)\n",
    "    average = GlobalAveragePooling1D()(layer)\n",
    "    concat = concatenate([maxpool, average], axis=1)\n",
    "    layer = Dropout(0.4)(concat)\n",
    "    layer = Dense(rec_units, activation=\"relu\")(layer)\n",
    "    output_layer = Dense(6, activation=\"sigmoid\")(layer)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRDJuRDMVE-L"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('processed_train.csv', index_col='id')\n",
    "test_X = pd.read_csv('processed_test.csv', index_col='id')\n",
    "test_y = pd.read_csv('test_labels.csv', index_col='id')\n",
    "types = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "y = train[types]\n",
    "test_y = test_y[types]\n",
    "X = train[['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WG7TIhetVE-N"
   },
   "outputs": [],
   "source": [
    "voc = {}\n",
    "i = 1\n",
    "emb_matrix = np.zeros((w2v.vectors.shape[0] + 1, w2v.vectors.shape[1]))\n",
    "for word in w2v.index2word:\n",
    "    voc[word] = i\n",
    "    emb_matrix[i] = w2v[word]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0M4V_YKyVE-P"
   },
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "\n",
    "train_features = pd.np.array(X['comment_text'].apply(lambda x: [voc[item] for item in x.split() \n",
    "                                                        if item in voc.keys()]))\n",
    "\n",
    "test_features = pd.np.array(test_X['comment_text'].apply(lambda x: [voc[item] for item in x.split() \n",
    "                                                        if item in voc.keys()]))\n",
    "\n",
    "for arr in train_features:\n",
    "    max_len = max(max_len, len(arr))\n",
    "    \n",
    "train_features = pad_sequences(train_features, maxlen=max_len, padding='post')\n",
    "    \n",
    "test_features = pad_sequences(test_features, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "colab_type": "code",
    "id": "ASRFUyseVE-R",
    "outputId": "21d9e80e-4459-40b9-8877-7cb613d2764b"
   },
   "outputs": [],
   "source": [
    "model = model_rnn(w2v.vectors.shape[0], w2v.vectors.shape[1], emb_matrix, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "y-jYstWYVE-U",
    "outputId": "f0f65f2d-acc0-4e69-b2b4-2d2de7e6f17e"
   },
   "outputs": [],
   "source": [
    "сheckpoint = ModelCheckpoint(\"save/weights_lstm.{epoch:02d}-{val_loss:.2f}.hdf5\")\n",
    "epochs = 3\n",
    "model.fit(train_features, pd.np.array(y), epochs = epochs, verbose=1, validation_split=0.2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Se79xt7FVE-k"
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "json_file = open(\"my_model1.json\", \"w\")\n",
    "json_file.write(model_json)\n",
    "json_file.close()\n",
    "model.save_weights(\"my_model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-ThGRB_VE-W"
   },
   "outputs": [],
   "source": [
    "print('Test')\n",
    "pred_proba = model.predict(test_features, batch_size= 256)\n",
    "print('Train')\n",
    "pred_proba_train = model.predict(train_features, batch_size= 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "YFzZh6GOVE-Y",
    "outputId": "ebc97463-9a0d-4a98-e584-ef554d97e6ca"
   },
   "outputs": [],
   "source": [
    "print('Test:')\n",
    "score_ra = 0\n",
    "score_ll = 0\n",
    "for i in range(0, len(types)):\n",
    "    print(types[i], ':')\n",
    "    pred = [x[i] for x in pred_proba]\n",
    "    ra = roc_auc_score(test_y[types[i]], pred)\n",
    "    ll = log_loss(test_y[types[i]], pred, eps = 1e-7)\n",
    "    score_ra += ra\n",
    "    score_ll += ll\n",
    "    print('roc_auc:', ra)\n",
    "    print('log_loss:',ll)\n",
    "print(\"Score roc_auc:\", score_ra/len(types))\n",
    "print(\"Score log_loss:\", score_ll/len(types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "Be53WTKvVE-a",
    "outputId": "22b7b173-ae09-4a7f-e89f-883232230c7a"
   },
   "outputs": [],
   "source": [
    "print('Train:')\n",
    "score_ra = 0\n",
    "score_ll = 0\n",
    "for i in range(0, len(types)):\n",
    "    print(types[i], ':')\n",
    "    pred = [x[i] for x in pred_proba_train]\n",
    "    ra = roc_auc_score(y[types[i]], pred)\n",
    "    ll = log_loss(y[types[i]], pred, eps = 1e-7)\n",
    "    score_ra += ra\n",
    "    score_ll += ll\n",
    "    print('roc_auc:', ra)\n",
    "    print('log_loss:',ll)\n",
    "print(\"Score roc_auc:\", score_ra/len(types))\n",
    "print(\"Score log_loss:\", score_ll/len(types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "eiHbGWU8VE-f",
    "outputId": "ca16842a-0c10-4bde-8018-4203ecfce20f"
   },
   "outputs": [],
   "source": [
    "сheckpoint = ModelCheckpoint(\"save/weights_lstm2.{epoch:02d}-{val_loss:.2f}.hdf5\")\n",
    "epochs = 3\n",
    "model.fit(train_features, pd.np.array(y), epochs = epochs, verbose=1, validation_split=0.2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IOatb2SoVE-m",
    "outputId": "58295228-9423-404b-c200-52a43970a2b1"
   },
   "outputs": [],
   "source": [
    "print('Test')\n",
    "pred_proba = model.predict(test_features, batch_size=256)\n",
    "print('Train')\n",
    "pred_proba_train = model.predict(train_features, batch_size= 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "lXWnAw7iVE-g",
    "outputId": "0375eaff-4b13-4b6b-fcaf-2695b3e51cf5"
   },
   "outputs": [],
   "source": [
    "print('Test:')\n",
    "score_ra = 0\n",
    "score_ll = 0\n",
    "for i in range(0, len(types)):\n",
    "    print(types[i], ':')\n",
    "    pred = [x[i] for x in pred_proba]\n",
    "    ra = roc_auc_score(test_y[types[i]], pred)\n",
    "    ll = log_loss(test_y[types[i]], pred, eps = 1e-7)\n",
    "    score_ra += ra\n",
    "    score_ll += ll\n",
    "    print('roc_auc:', ra)\n",
    "    print('log_loss:',ll)\n",
    "print(\"Score roc_auc:\", score_ra/len(types))\n",
    "print(\"Score log_loss:\", score_ll/len(types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "CSVhpmipVE-i",
    "outputId": "60bc1655-709f-48d9-e6bd-2d45fa11d811"
   },
   "outputs": [],
   "source": [
    "print('Train:')\n",
    "score_ra = 0\n",
    "score_ll = 0\n",
    "for i in range(0, len(types)):\n",
    "    print(types[i], ':')\n",
    "    pred = [x[i] for x in pred_proba_train]\n",
    "    ra = roc_auc_score(y[types[i]], pred)\n",
    "    ll = log_loss(y[types[i]], pred, eps = 1e-7)\n",
    "    score_ra += ra\n",
    "    score_ll += ll\n",
    "    print('roc_auc:', ra)\n",
    "    print('log_loss:',ll)\n",
    "print(\"Score roc_auc:\", score_ra/len(types))\n",
    "print(\"Score log_loss:\", score_ll/len(types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fu5Ls1faVE-s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "model_keras_type1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
